{
 "cells": [
  {
   "cell_type": "raw",
   "id": "731e517c-7bc7-4499-9fe8-00f1599f42f0",
   "metadata": {},
   "source": [
    "'''\n",
    "------------------------------------------------------------------------------\n",
    "   Copyright 2024 Murali Kashaboina\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License.\n",
    "------------------------------------------------------------------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db98a99a-85f3-4312-b038-5f64c254101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from som_based_rag import SOM_Based_RAG_Util\n",
    "\n",
    "from wiki_datasource import WikiEventsDataSource\n",
    "\n",
    "from openai_vector_encoder import OpenAIEmbeddingsVectorEncoder\n",
    "\n",
    "from openai_qa_chatbot import OpenAIQuestionAnswerChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d655453b-0e4f-4216-8987-7e9f5f72f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc95728-72f5-4c19-a9e5-091d402ea0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = \"sk-proj-cecR6SLBRlGmjFNWFkpPT3BlbkFJtR4vtIrgsuIxZB8yJJWc\"\n",
    "\n",
    "openai_vector_encoder_id = \"text-embedding-ada-002\"\n",
    "\n",
    "openai_encoded_vector_dimensions = 1536\n",
    "\n",
    "openai_tokenizer_name = \"cl100k_base\" \n",
    "\n",
    "openai_model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "vector_encoder = OpenAIEmbeddingsVectorEncoder( openai_encoded_vector_dimensions, openai_vector_encoder_id, openai_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6c5da9-c735-4de4-9dcd-cc5acff04125",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_years_to_fetch = [ 2022, 2023, 2024 ]\n",
    "data_source = WikiEventsDataSource( event_years_to_fetch  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a977b7-28d3-4cc0-8461-072aa7e3f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_driven_rag_util = SOM_Based_RAG_Util( \n",
    "                                            vector_encoder = vector_encoder,\n",
    "                                            som_lattice_height = 20,\n",
    "                                            som_lattice_width = 30,\n",
    "                                            learning_rate = 0.3,\n",
    "                                            topk_bmu_for_indexing = 10,\n",
    "                                            device = device\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d466bc1-882b-46b6-9d0f-d5e480344fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3678b877d5eb4e4c9f0edfa0f857f94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vectorized Data Batch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m som_driven_rag_util\u001b[38;5;241m.\u001b[39mload_n_vectorize_data( data_source )\n",
      "File \u001b[1;32m~\\Desktop\\DataScience\\som-driven-qa-rag-main\\som_based_rag.py:178\u001b[0m, in \u001b[0;36mSOM_Based_RAG_Util.load_n_vectorize_data\u001b[1;34m(self, data_source)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm( \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorize_batch_size ), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorized Data Batch\u001b[39m\u001b[38;5;124m\"\u001b[39m ):\n\u001b[0;32m    176\u001b[0m     list_of_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[ i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorize_batch_size ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 178\u001b[0m     batch_encoded_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_encoder\u001b[38;5;241m.\u001b[39mencode_batch( list_of_text )\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectors \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m         vectors \u001b[38;5;241m=\u001b[39m batch_encoded_vectors\n",
      "File \u001b[1;32m~\\Desktop\\DataScience\\som-driven-qa-rag-main\\openai_vector_encoder.py:70\u001b[0m, in \u001b[0;36mOpenAIEmbeddingsVectorEncoder.encode_batch\u001b[1;34m(self, list_of_text)\u001b[0m\n\u001b[0;32m     66\u001b[0m list_of_text \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;28mstr\u001b[39m( text ) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text ]\n\u001b[0;32m     68\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_key\n\u001b[1;32m---> 70\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mEmbedding\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     71\u001b[0m                                     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m list_of_text,\n\u001b[0;32m     72\u001b[0m                                     engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_encoder_id\n\u001b[0;32m     73\u001b[0m                                   )\n\u001b[0;32m     75\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m [ data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] ] \n\u001b[0;32m     77\u001b[0m vectors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor( embeddings, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    712\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "som_driven_rag_util.load_n_vectorize_data( data_source )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b9b4e-7213-42a4-9621-7dc421d9f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_driven_rag_util.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca31b5-c2d1-41d8-b797-f0cd557a0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_driven_rag_util.train_n_index_data_vectors( train_epochs = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d985a5-f6db-497d-b809-0d0e10269cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_driven_rag_util.find_semantically_similar_data( \"Who aquired Twitter in 2022?\", sim_threshold = 0.8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d25b4-8737-4a26-a3e7-3168db4090f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_chatbot = OpenAIQuestionAnswerChatBot( \n",
    "                                                vector_db_util = som_driven_rag_util,\n",
    "                                                openai_tokenizer_name = openai_tokenizer_name,\n",
    "                                                openai_model_name = openai_model_name,\n",
    "                                                openai_key = openai_key,\n",
    "                                                question_input_max_token_count = 100,\n",
    "                                                context_trim_percent = 0.1,\n",
    "                                                device = device\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9872300-f18e-4ca6-b488-63ba76f170bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = [\n",
    "                        \"Who won the 2022 soccer world cup?\",\n",
    "                        \"When did Sweden join NATO?\",\n",
    "                        \"Who joined NATO in 2023?\",\n",
    "                        \"Who joined NATO in 2024?\",\n",
    "                        \"Which is the 31st member of NATO?\",\n",
    "                        \"Which is the 32nd member of NATO?\",\n",
    "                        \"Who won the Cricket World Cup in 2023?\",\n",
    "                        \"Who defeated India in Cricket World Cup final in 2023?\",\n",
    "                        \"Name the former prime minister of Japan that was assassinated in 2022?\",\n",
    "                        \"When did Chandrayaan-3 land near the south pole of the Moon?\",\n",
    "                        \"Where did Chandrayaan-3 land on the Moon?\",\n",
    "                        \"Who acquired Twitter in 2022?\",\n",
    "                        \"Who owns Twitter?\",\n",
    "                        \"Who acquired Activision Blizzard in 2023?\"\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed35e14-c9d7-4c97-a5f3-4284f91c832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_question in sample_questions:\n",
    "    print( f\"\\nQuestion: {sample_question}\" )\n",
    "    answer = openai_chatbot.find_answer_to_question_without_context( sample_question )\n",
    "    print( f\"Answer: {answer}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95045b-c572-4365-b3ce-48193603635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_threshold = 0.75\n",
    "\n",
    "for sample_question in sample_questions:\n",
    "    print( f\"\\nQuestion: {sample_question}\" )\n",
    "    answer = openai_chatbot.find_answer_to_question( sample_question, sim_threshold = sim_threshold)\n",
    "    print( f\"Answer: {answer}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9c4ba-f692-401d-8f55-58b64c8de3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9219ed1-6c8e-4738-a9cd-71054b1a9e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6d726-6431-4ff9-8083-ffe596c9ad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e2b44-6e22-4ba6-8bec-1ebeaa0b12ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
